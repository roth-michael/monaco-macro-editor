
    export default [
      "@league-of-foundry-developers/foundry-vtt-types/src/foundry/foundry.js/audioHelper.d.ts",
      "/**\n * A helper class to provide common functionality for working with the Web Audio API.\n * https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API\n * A singleton instance of this class is available as game#audio.\n * @see Game#audio\n */\ndeclare class AudioHelper {\n  constructor();\n\n  /**\n   * The primary Audio Context used to play client-facing sounds.\n   * The context is undefined until the user's first gesture is observed.\n   * @defaultValue `undefined`\n   */\n  context: AudioContext | undefined;\n\n  /**\n   * The set of AudioBuffer objects which are cached for different audio paths\n   */\n  buffers: Map<string, AudioBuffer>;\n\n  /**\n   * The set of singleton Sound instances which are cached for different audio paths\n   */\n  sounds: Map<string, Sound>;\n\n  /**\n   * Get a map of the Sound objects which are currently playing.\n   * @remarks It's not actually an `Array` but a `Map`.\n   */\n  playing: Map<number, Sound>;\n\n  /**\n   * A user gesture must be registered before audio can be played.\n   * This Array contains the Sound instances which are requested for playback prior to a gesture.\n   * Once a gesture is observed, we begin playing all elements of this Array.\n   * @see Sound\n   * @defaultValue `[]`\n   */\n  pending: (() => void)[];\n\n  /**\n   * A flag for whether video playback is currently locked by awaiting a user gesture\n   * @defaultValue `true`\n   */\n  locked: boolean;\n\n  /**\n   * Audio Context singleton used for analysing audio levels of each stream\n   * Only created if necessary to listen to audio streams.\n   * @defaultValue `null`\n   * @internal\n   */\n  protected _audioContext: AudioContext | null;\n\n  /**\n   * Map of all streams that we listen to for determining the decibel levels.\n   * Used for analyzing audio levels of each stream.\n   * Format of the object stored is :\n   * ```\n   * {id:\n   *   {\n   *     stream: MediaStream,\n   *     analyser: AudioAnalyser,\n   *     interval: Number,\n   *     callback: Function\n   *   }\n   * }\n   * ```\n   * @internal\n   */\n  protected _analyserStreams: Record<string, AudioHelper.AnalyserStream>;\n\n  /**\n   * Interval ID as returned by setInterval for analysing the volume of streams\n   * When set to 0, means no timer is set.\n   * @defaultValue `0`\n   * @internal\n   */\n  protected _analyserInterval: number;\n\n  /**\n   * Fast Fourier Transform Array.\n   * Used for analysing the decibel level of streams. The array is allocated only once\n   * then filled by the analyser repeatedly. We only generate it when we need to listen to\n   * a stream's level, so we initialize it to null.\n   * @defaultValue `null`\n   * @internal\n   */\n  protected _fftArray: Float32Array | null;\n\n  /**\n   * The Native interval for the AudioHelper to analyse audio levels from streams\n   * Any interval passed to startLevelReports() would need to be a multiple of this value.\n   * @defaultValue `50`\n   */\n  static levelAnalyserNativeInterval: number;\n\n  /**\n   * Register client-level settings for global volume overrides\n   */\n  static registerSettings(): void;\n\n  /**\n   * Create a Sound instance for a given audio source URL\n   * @param options - Audio creation options\n   */\n  create(options: AudioHelper.CreateOptions): Sound;\n\n  /**\n   * Test whether a source file has a supported audio extension type\n   * @param src - A requested audio source path\n   * @returns Does the filename end with a valid audio extension?\n   */\n  static hasAudioExtension(src: string): boolean;\n\n  /**\n   * Given an input file path, determine a default name for the sound based on the filename\n   * @param src - An input file path\n   * @returns A default sound name for the path\n   */\n  static getDefaultSoundName(src: string): string;\n\n  /**\n   * Play a single Sound by providing its source.\n   * @param src     - The file path to the audio source being played\n   * @param options - Additional options passed to Sound#play\n   * @returns The created Sound which is now playing\n   */\n  play(src: string, options?: Sound.PlayOptions): Promise<Sound>;\n\n  /**\n   * Register an event listener to await the first mousemove gesture and begin playback once observed\n   */\n  awaitFirstGesture(): void;\n\n  /**\n   * Request that other connected clients begin preloading a certain sound path.\n   * @param src - The source file path requested for preload\n   * @returns A Promise which resolves once the preload is complete\n   */\n  preload(src: string): Promise<Sound>;\n\n  /**\n   * Open socket listeners which transact ChatMessage data\n   * @internal\n   */\n  static _activateSocketListeners(socket: io.Socket): void;\n\n  /**\n   * Play a one-off sound effect which is not part of a Playlist\n   *\n   * @param data - An object configuring the audio data to play\n   * @param push - Push the audio sound effect to other connected clients?\n   *               (default: `false`)\n   *\n   * @returns A Sound instance which controls audio playback.\n   *\n   * @example\n   * ```typescript\n   * // Play the sound of a locked door for all players\n   * AudioHelper.play({src: \"sounds/lock.wav\", volume: 0.8, loop: false}, true);\n   * ```\n   */\n  static play(data: AudioHelper.PlayData, push?: boolean): Promise<Sound>;\n\n  /**\n   * Begin loading the sound for a provided source URL adding its\n   * @param src - The audio source path to preload\n   * @returns The created and loaded Sound ready for playback\n   */\n  static preloadSound(src: string): Promise<Sound>;\n\n  /**\n   * Returns the volume value based on a range input volume control's position.\n   * This is using an exponential approximation of the logarithmic nature of audio level perception\n   * @param value - Value between [0, 1] of the range input\n   * @param order - The exponent of the curve\n   *                (default: `1.5`)\n   */\n  static inputToVolume(value: number | string, order?: number): number;\n\n  /**\n   * Counterpart to inputToVolume()\n   * Returns the input range value based on a volume\n   * @param volume - Value between [0, 1] of the volume level\n   * @param order  - The exponent of the curve\n   */\n  static volumeToInput(volume: number, order?: number): number;\n\n  /**\n   * Returns a singleton AudioContext if one can be created.\n   * An audio context may not be available due to limited resources or browser compatibility\n   * in which case null will be returned\n   *\n   * @returns A singleton AudioContext or null if one is not available\n   */\n  getAudioContext(): AudioContext | null;\n\n  /**\n   * Registers a stream for periodic reports of audio levels.\n   * Once added, the callback will be called with the maximum decibel level of\n   * the audio tracks in that stream since the last time the event was fired.\n   * The interval needs to be a multiple of `AudioHelper.levelAnalyserNativeInterval` which defaults at 50ms\n   *\n   * @param id        - An id to assign to this report. Can be used to stop reports\n   * @param stream    - The MediaStream instance to report activity on.\n   * @param callback  - The callback function to call with the decibel level.\n   * @param interval  - The interval at which to produce reports.\n   *                    (default: `50`)\n   * @param smoothing - The smoothingTimeConstant to set on the audio analyser. Refer to AudioAnalyser API docs.\n   *                    (default: `0.1`)\n   * @returns Returns whether or not listening to the stream was successful\n   */\n  startLevelReports(\n    id: string,\n    stream: MediaStream,\n    callback: (maxDecibel: number, fftArray: Float32Array) => void,\n    interval?: number,\n    smoothing?: number\n  ): boolean | undefined;\n\n  /**\n   * Stop sending audio level reports\n   * This stops listening to a stream and stops sending reports.\n   * If we aren't listening to any more streams, cancel the global analyser timer.\n   * @param id - The id of the reports that passed to startLevelReports.\n   */\n  stopLevelReports(id: string): void;\n\n  /**\n   * Ensures the global analyser timer is started\n   *\n   * We create only one timer that runs every 50ms and only create it if needed, this is meant to optimize things\n   * and avoid having multiple timers running if we want to analyse multiple streams at the same time.\n   * I don't know if it actually helps much with performance but it's expected that limiting the number of timers\n   * running at the same time is good practice and with JS itself, there's a potential for a timer congestion\n   * phenomenon if too many are created.\n   * @internal\n   */\n  protected _ensureAnalyserTimer(): void;\n\n  /**\n   * Cancel the global analyser timer\n   * If the timer is running and has become unnecessary, stops it.\n   * @internal\n   */\n  protected _cancelAnalyserTimer(): void;\n\n  /**\n   * Capture audio level for all speakers and emit a webrtcVolumes custom event with all the volume levels\n   * detected since the last emit.\n   * The event's detail is in the form of `{userId: decibelLevel}`\n   * @internal\n   */\n  protected _emitVolumes(): void;\n\n  /**\n   * Handle the first observed user gesture\n   * @param event - The mouse-move event which enables playback\n   * @internal\n   */\n  protected _onFirstGesture(event: Event): void;\n\n  /**\n   * Additional standard callback events that occur whenever a global volume slider is adjusted\n   * @param key    - The setting key\n   * @param volume - The new volume level\n   * @internal\n   */\n  protected _onChangeGlobalVolume(key: string, volume: number): void;\n}\n\ndeclare namespace AudioHelper {\n  interface AnalyserStream {\n    stream: MediaStream;\n    analyser: AnalyserNode;\n    interval: number;\n    callback: (maxDecibel: number, fftArray: Float32Array) => void;\n\n    /**\n     * Used as a counter of 50ms increments in case the interval is more than 50\n     * @defaultValue `0`\n     * @internal\n     */\n    _lastEmit: number;\n  }\n  interface CreateOptions {\n    /**\n     * The source URL for the audio file\n     */\n    src: string;\n\n    /**\n     * Reuse an existing Sound for this source?\n     * @defaultValue `true`\n     */\n    singleton?: boolean;\n\n    /**\n     * Begin loading the audio immediately?\n     * @defaultValue `false`\n     */\n    preload?: boolean;\n\n    /**\n     * Begin playing the audio as soon as it is ready?\n     * @defaultValue `false`\n     */\n    autoplay?: boolean;\n\n    /**\n     * Additional options passed to the play method if autoplay is true\n     * @defaultValue `{}`\n     */\n    autoplayOptions?: Sound.PlayOptions;\n  }\n\n  interface PlayData {\n    /**\n     * The audio source file path, either a public URL or a local path relative to the public directory\n     */\n    src: string;\n\n    /**\n     * The volume level at which to play the audio, between 0 and 1.\n     * @defaultValue `1.0`\n     */\n    volume?: number;\n\n    /**\n     * Begin playback of the audio effect immediately once it is loaded.\n     * @deprecated You are using the autoplay option of AudioHelper.play which is no longer supported in 0.8.0\n     */\n    autoplay?: boolean;\n\n    /**\n     * Loop the audio effect and continue playing it until it is manually stopped.\n     * @defaultValue `false`\n     */\n    loop?: boolean;\n  }\n}\n"
    ]
  