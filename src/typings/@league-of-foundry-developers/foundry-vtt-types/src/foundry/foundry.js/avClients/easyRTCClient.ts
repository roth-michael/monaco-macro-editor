
    export default [
      "@league-of-foundry-developers/foundry-vtt-types/src/foundry/foundry.js/avClients/easyRTCClient.d.ts",
      "/**\n * An AVClient implementation that uses WebRTC and the EasyRTC library.\n * This client is deprecated and will be removed entirely in 0.9.x.\n *\n * If you wish to continue using it, you will need to manually enable it by:\n * 1. Include the easyrtc.js library which is no longer served\n * 2. Set CONFIG.WebRTC.clientClass = EasyRTCClient\n *\n * @deprecated since 0.8.7 */\ndeclare class EasyRTCClient extends AVClient {\n  /**\n   * @param master   - The master orchestration instance\n   * @param settings - The audio/video settings being used\n   */\n  constructor(master: AVMaster, settings: AVSettings);\n\n  /**\n   * Store the name of the joined EasyRTC room\n   * @defaultValue `null`\n   */\n  protected _room: string | null;\n\n  /**\n   * A mapping of easyRtcId peer ids to Foundry User ids\n   * @defaultValue `{}`\n   */\n  protected _usernameCache: Record<string, string>;\n\n  /**\n   * An array of easyRtcId peers that rejected our call. Avoid continually trying to call the same peer.\n   * @defaultValue `[]`\n   */\n  protected _callRejections: string[];\n\n  /** @override */\n  initialize(): Promise<void>;\n\n  /** @override */\n  connect(): Promise<true>;\n\n  /** @override */\n  disconnect(): Promise<true>;\n\n  /**\n   * Connect to the WebRTC server and configure ICE/TURN servers\n   * @returns Was the server connected?\n   */\n  protected _connectServer({\n    type,\n    room,\n    url,\n    username,\n    password\n  }: {\n    type?: 'FVTT' | 'custom';\n    room?: string;\n    url: string;\n    username: string;\n    password: string;\n  }): Promise<boolean>;\n\n  /**\n   * Setup the custom TURN relay to be used in subsequent calls if there is one configured\n   * If configured, setup custom TURN configuration for future calls. Turn credentials are mandatory in WebRTC.\n   */\n  protected _setupCustomTURN(): void;\n\n  /**\n   * Initialize a local media stream\n   * Capture the local audio and video and returns the stream associated with them.\n   *\n   * If `temporary` is false (default), then this will initialize the master stream, not the actual\n   * streams being sent to individual users. However, if a master stream was already created, it\n   * will automatically get closed and every individual streams derived from it that are being sent\n   * to connected users will be removed from the calls.\n   * Each established or subsequent calls will receive a copy of the created stream (A/V depending on user permissions)\n   *\n   * If `temporary` is true then this only applies to a temporary stream and does not affect\n   * the master stream or any streams in existing calls.\n   * Note that this assumes only one temporary stream can be created at a time.\n   *\n   * @param audioSrc  - ID of the audio source to capture from or null to disable Audio\n   *                    (default: `undefined`)\n   * @param videoSrc  - ID of the video source to capture from or null to disable Video\n   *                    (default: `undefined`)\n   * @param temporary - Whether to create a temporary stream or the master stream\n   *                    (default: `false`)\n   * @returns Returns the local stream or `null` if none could be created\n   */\n  protected _initializeLocal({\n    audioSrc,\n    videoSrc,\n    temporary\n  }?: {\n    audioSrc?: string | null;\n    videoSrc?: string | null;\n    temporary?: boolean;\n  }): Promise<MediaStream>;\n\n  /**\n   * Create an open a local stream when initially connecting to the server.\n   * This local stream becomes the \"master\" stream which tracks your own device inputs.\n   * The master stream is cloned to provide a stream to every connected peer.\n   */\n  protected _openLocalStream(\n    audioSrc: string | undefined | null,\n    videoSrc: string | undefined | null,\n    temporary?: boolean\n  ): Promise<MediaStream | null>;\n\n  /**\n   * Close the local stream\n   */\n  protected _closeLocalStream(temporary?: boolean): void;\n\n  /**\n   * Define media constraints to control the resolution and devices used.\n   * We need to set our own constraints so we can specify a min/max range of resolutions.\n   */\n  protected _getStreamMediaConstraints(\n    videoSrc: string | undefined | null,\n    audioSrc: string | undefined | null\n  ): EasyRTCClient.StreamMediaConstraints;\n\n  /**\n   * Call a peer and establish a connection with them\n   * @param easyRtcId - The peer ID to call\n   * @returns Returns false if no call was made or true if the call is successful.\n   * @throws raises an Exception in case of failure to establish the call.\n   */\n  protected _performCall(easyRtcId: string): Promise<boolean>;\n\n  /**\n   * Create a MediaStream to be sent to a specific peer.\n   * This stream should control whether outbound video and audio is transmitted.\n   * Create the stream as a clone of the current master stream for configuration on a peer-to-peer basis.\n   */\n  protected _createStreamForPeer(peer: string): MediaStream | null;\n\n  /** @override */\n  getAudioSinks(): Promise<Record<string, string>>;\n\n  /** @override */\n  getAudioSources(): Promise<Record<string, string>>;\n\n  /** @override */\n  getVideoSources(): Promise<Record<string, string>>;\n\n  /**\n   * Transform the device info array from easyrtc into an object with `{id: label}` keys\n   * @param list - The list of devices\n   */\n  protected _deviceInfoToObject(list: EasyRTCClient.DeviceSource[]): Record<string, string>;\n\n  /**\n   * Obtain the EasyRTC user ID of a user based on their Foundry VTT user ID\n   * @param userId - The ID of the user\n   * @returns The EasyRtcId of the peer\n   */\n  protected _userIdToEasyRtcId(userId: string): string | null;\n\n  /** @override */\n  getConnectedUsers(): string[];\n\n  /**\n   * Get MediaStream instances for every connected peer in the room.\n   * @returns - An array of stream information for each peer\n   */\n  getConnectedStreams(): EasyRTCClient.StreamInfo;\n\n  /** @override */\n  getMediaStreamForUser(userId: string): MediaStream;\n\n  /** @override */\n  isAudioEnabled(): boolean;\n\n  /** @override */\n  isVideoEnabled(): boolean;\n\n  /**\n   * Handle a request to enable or disable the outbound audio feed for the current game user.\n   * @param enable - Whether the outbound audio track should be enabled (true) or disabled (false)\n   */\n  toggleAudio(enable: boolean): void;\n\n  /**\n   * Set whether the outbound audio feed for the current game user is actively broadcasting.\n   * This can only be true if audio is enabled, but may be false if using push-to-talk or voice activation modes.\n   * @param broadcast - Whether outbound audio should be sent to connected peers or not?\n   */\n  toggleBroadcast(broadcast: boolean): void;\n\n  /**\n   * Handle a request to enable or disable the outbound video feed for the current game user.\n   * @param enable - Whether the outbound video track should be enabled (true) or disabled (false)\n   */\n  toggleVideo(enable: boolean): void;\n\n  /** @override */\n  setUserVideo(userId: string, videoElement: HTMLVideoElement): Promise<void>;\n\n  /**\n   * Enable or disable the audio tracks in a stream\n   *\n   * Disabling a track represents what a typical user would consider muting it.\n   * We use the term 'enable' here instead of 'mute' to match the MediaStreamTrack\n   * field name and to avoid confusion with the 'muted' read-only field of the MediaStreamTrack\n   * as well as the video element's `muted` field which only stops playing the audio.\n   * Muting by definition stops rendering any of the data, while a disabled track in this case\n   * is still rendering its data, but is simply generating disabled content (silence and black frames)\n   * See https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack/enabled\n   *\n   * @param stream - The stream to modify\n   * @param enable - (optional) Whether to enable or disable the tracks\n   *                 (default: `true`)\n   */\n  enableStreamAudio(stream: MediaStream, enable?: boolean): void;\n\n  /**\n   * Enable or disable the video tracks in a stream\n   *\n   * Disabling a track represents what a typical user would consider muting it. We use the term 'enable' here instead\n   * of 'mute' to match the MediaStreamTrack field name and to avoid confusion with the 'muted' read-only field of the\n   * MediaStreamTrack as well as the video element's `muted` field which only stops playing the audio.\n   *\n   * Muting by definition stops rendering any of the data, while a disabled track in this case is still rendering its\n   * data, but is simply generating disabled content (silence and black frames).\n   *\n   * See https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack/enabled\n   *\n   * @param stream - The stream to modify\n   * @param enable - (optional) Whether to enable or disable the tracks\n   *                 (default: `true`)\n   */\n  enableStreamVideo(stream: MediaStream, enable?: boolean): void;\n\n  /**\n   * Enables or disables media tracks\n   * See https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack/enabled\n   * @param tracks - The tracks to enable/disable\n   * @param enable - Whether to enable or disable the tracks\n   */\n  protected _enableMediaTracks(tracks: MediaStreamTrack[], enable: boolean): void;\n\n  /**\n   * Callback used to check if an incoming call should be accepted or not\n   * @param easyRtcId - The peer ID of the caller\n   * @param acceptor  - Function to call with whether or not to accept the call and the media streams to use\n   */\n  protected _answerIncomingCall(\n    easyRtcId: string,\n    acceptor: (accept: boolean, streamNames: string[] | null) => unknown\n  ): void;\n\n  /**\n   * Called when the connection to the signaling server is lost (unintentionally).\n   * This handles the case of when connectivity is interrupted non-deliberately.\n   */\n  protected _onConnectionLost(): void;\n\n  /**\n   * Called when an error occurs\n   */\n  protected _onError({ errorCode, errorText }: { errorCode: string; errorText: string }): void;\n\n  /**\n   * Called whenever there is a change in the list of occupants in a room.\n   * It can also be called if a peer's state changes, such as when a call is established or ended.\n   * For each other peer in the room, record their user ID and establish a call with them.\n   * Record the username associated with each peer.\n   *\n   * Important: We need to make sure that only user initiates a call, instead of both trying to call each other.\n   * Resolve this by having the alphabetically greater ID call the other peer.\n   *\n   * @param roomName    - The room name where occupants have changed\n   * @param otherPeople - An array of other peers in the room\n   * @param myInfo      - My own connection info\n   */\n  protected _onRoomOccupantsChange(\n    roomName: string,\n    otherPeople: Record<string, any>,\n    myInfo: { easyrtcid: string; [key: string]: any }\n  ): Promise<void>;\n\n  /**\n   * Called when the connection with a peer has been established\n   */\n  protected onPeerOpen(easyRtcId: string): void;\n\n  /**\n   * Called when the connection with a peer has been lost and the ICE machine was unable to re-establish it.\n   * In case of irrecoverable connection loss with the peer, hanging up the call will cause a roomOccupantListener\n   * signal to be sent and we will automatically try to reconnect to the user.\n   * First make sure that they are still in the room so we don't try to hangup with an easyRtcId that is invalid.\n   */\n  protected _onPeerClosed(easyRtcId: string): void;\n\n  /**\n   * Called when a remote stream is added to an existing call\n   */\n  protected _onPeerConnect(easyRtcId: string, stream: MediaStream): void;\n\n  /**\n   * Called when a remote stream is removed from an existing call\n   */\n  protected _onPeerDisconnect(easyRtcId: string, stream: MediaStream, streamName: string): void;\n\n  /**\n   * @deprecated Use `getMediaStreamForUser` instead\n   */\n  getStreamForUser(userId: string): MediaStream;\n}\n\ndeclare namespace EasyRTCClient {\n  interface StreamMediaConstraints {\n    video:\n      | {\n          /**\n           * @defaultValue `4/3`\n           */\n          aspectRatio: number;\n\n          width: {\n            /**\n             * @defaultValue `32=`\n             */\n            ideal: number;\n\n            /**\n             * @defaultValue `640`\n             */\n            max: number;\n\n            /**\n             * @defaultValue `160`\n             */\n            min: number;\n          };\n\n          height: {\n            /**\n             * @defaultValue `240`\n             */\n            ideal: number;\n\n            /**\n             * @defaultValue `480`\n             */\n            max: number;\n\n            /**\n             * @defaultValue `120`\n             */\n            min: number;\n          };\n\n          frameRate: {\n            /**\n             * @defaultValue `15`\n             */\n            ideal: number;\n\n            /**\n             * @defaultValue `30`\n             */\n            max: number;\n          };\n\n          deviceId: string | undefined | null;\n        }\n      | false;\n    audio:\n      | {\n          deviceId: string | undefined | null;\n        }\n      | false;\n  }\n\n  interface DeviceSource {\n    deviceId: string;\n    groupId: string;\n    label: string;\n    kind: 'audio' | 'video';\n  }\n\n  interface StreamInfo {\n    id: string;\n    connection: RTCPeerConnection;\n    local: MediaStream | null;\n    remote: MediaStream | null;\n  }\n}\n"
    ]
  